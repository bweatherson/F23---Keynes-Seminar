# Weight

## A Story

Here's the basic idea. Someone is doing an investigation into a particular proposition $p$. Let's say $p$ is a particular theory about the origins of COVID-19.^[There are wild conspiracies about this which I think should be set aside. But to the best of my knowledge, there are reasonable grounds for uncertainty about even the basic timeline. So it's a good example of something we can be very uncertain about.] The evidence here is a complete mess, partially because the questions are very hard, and partially because the Chinese government isn't exactly helpful.^[To be sure, I'm not sure which government would be.] So the inquirer might often get evidence that supports $p$ one day, and then opposes it the next.

Keynes has this mental picture of the investigator having an old fashioned scale. When the evidence comes in, they classify it as either for or against $p$, and place it on the scale. How much the scale tips says something about the probability of $p$.

As the investigation continues, the probability might move in all sorts of directions. One side or the other of the balance might have more 'weight' on it. But, says Keynes, the total evidence keeps going up. The difference between the sides might change, and change direction. But the sum of the sides keeps rising as we add more things to one or other pan.

That's the picture at least. And the thought is given that picture of how evidence is accumulated, there is some interest in this value of the sum of the evidence, not just its difference. Actually, maybe we'll come back to this, is it difference or ratio that a balance beam is sensitive to? I guess it's difference. Anyway, that's the picture.

## A Problem

### Setting Up the Problem

Our investigator is bored one day, so they start flipping a coin. And, being an investigator, they write the results down. First Tails, then Heads, then three Tails in a row, and so on. The effect this has on the investigation is zero; completely and utterly zero. This doesn't add anything to the investigation. It is evidence; it could affect our probability that the coin is biased. But it isn't evidence that's relevant this investigation.^[If weight is just a function of how much total evidence one has, then we'd have $V(a/h) = V(b/h)$ for any $a, b$. And Keynes explicitly doesn't want that.] So it shouldn't add to the weight.

That sounds like an easy enough problem to solve. Say that $V(a/hh_1) = V(a/h)$ if $a/hh_1 = a/h$. That is, if $h_1$ doesn't change the probability of $a$, it doesn't change the weight of $a/h$. In this case, $a$ is the old hypothesis about COVID-19, $h$ is the old evidence, and $h_1$ is that this coin flip landed heads.

Unfortunately, there are several problems with this. Start with the following problem. Imagine that there are two investigators looking into $p$. One of them is off sick for a couple of days. While they are out, the first investigator discovers $h_2$, which raises the probability of $p$. On Tuesday, they discover $h_3$, which lowers the probability of $p$. On Wednesday, when the second investigator comes back to work, and they are told of what was found while they were away, i.e., $h_2h_3$, the probability of $p$ is unchanged. But the weight has surely risen. After all, it rose on Monday and again on Tuesday. So adding $h_2h_3$ raises the weight. So sometimes, adding an independent bit of evidence raises the weight.

There is a formal version of this problem. Assume that for any $x, y, z$, if $y, z$ are logically equivalent, then $V(x/y) = V(x/z)$. That is, assume substitutivity of logical equivalents within a weight operator. Then note that $h_1$ is logically equivalent to $(h_1 \vee p) \wedge (h_1 \vee \neg p)$. Then we can reason as follows. I'll also assume something that I think we can't do without, namely that on the right hand side of $a/h$, set theoretic union is conjunction. That is, adding two bits of evidence is equivalent to adding their conjunction.^[Keynes certainly writes as if this is a trivial assumption in many places, and I don't think it's avoidable.] 

\begin{align*}
V(a/h) &= V(a/hh_1) \\
   &= V(a/h \wedge ((h_1 \vee p) \wedge (h_1 \vee \neg p)) \\
   &= V(a/h \cup \{h_1 \vee p\} \cup \{h_1 \vee \neg p\}) \\
   &> V(a/h \cup \{h_1 \vee p\}) \\
   &> V(a/h)
\end{align*}

And oops, we have a contradiction. How could we avoid this? I can see two options that are relatively simple, and which don't seem attractive, and one that is less simple, but might do the trick.

### Keynes's Solution

Keynes says, without quite realising it, that the argument fails at the first step. He says that independent evidence can add to weight as long as it's (equivalent to) a conjunction of two things that change the probability. And the problem, as Carnap pointed out and as Cohen also noted, was that everything is equivalent to the conjunction of two things that change the probability. So on Keynes's solution, flipping the coin does add weight.

### Denying Equivalence

Is there a way out of this? I'm not sure, but let's try some things. We could play with the idea that weight is a function of arguments, and arguments are made of sentences, not propositions. We don't have to say that if $y, z$ are equivalent, then $V(x/y) = V(x/z)$. We definitely do have that $x/y = x/z$, but Keynes explicitly rejects the inference from that to $V(x/y) = V(x/z)$.

Then we might say that evidence adds no weight if it is independent, and, if it is of the form $A \wedge B$, both $A$ and $B$ are independent.

I don't know how much trouble this will raise elsewhere. I kind of think this might work, but it's a big change at least to how we think about probability in contemporary work.

### Weight as Projection

Here's the thing about the coin flip. It's not just that it doesn't make a difference to the probability of $p$ now. We know (in some intuitive sense of 'know') that it won't make a difference going forward. It's not just irrelevant given $h$, it's irrelevant given any reasonable extension of $h$.

Compare this kind of case. We're gossiping and trying to figure out if Jack and Jill are dating. Someone adds that they saw Jack at a couple of places last night; having hamburgers early in the night at Blimpy and then at the comedy club later. That doesn't seem like it moves the probability that Jack and Jill are dating one way or the other. Then someone else adds that they saw Jill at both these places. That could be a coincidence, but that's a bit of interesting information.

So what's happened there is the first bit of information, where Jack was, is arguably independent of whether Jack and Jill are dating. And similarly on its own, the information about where Jill was, is also independent. But put those two pieces of information together, and now we have something. Hardly conclusive proof, but enough of a probability shifter to make fun gossip.

Intuitively, it seems that we want to say is that new evidence raises the weight if it changes the probability, or it could change the probability in the future. This doesn't on it's own solve the problem. Go back to the coin flip, and let $h_1$ be a proposition about the coin flip. For any $a$, we could learn $h_1 \supset a$, and then $h_1$ would be relevant. I think what's going on is that while we logically could learn that, it's not going to happen. There is no reasonable world in which we learn a material conditional connecting a coin flip to the origins of COVID, and nothing else. So here's my worked out hypothesis.

- Given $h$, there is a set $S$ of things that are possible items of future evidence.
- $V(a/hh_1) > V(a/h)$ iff for some $e \in S: a/heh_1 \neq a/he$.

This won't quite work for a reason we'll get to below, but it's progress. I think it helps with the two investigators problem. We could learn on Thursday that there was something wrong with the way the Monday or Tuesday investigations were conducted. And then $h_2h_3$ would be relevant to $p$. So I think this does the job that Keynes introduced general irrelevance to do. The problem is that there are three other issues that I don't think Keynes has the start of an answer to, and I'm not really sure what to say about them.

## Three More Problems

### How Many Scales?

The issue of how the weighing metaphor works is one of the biggest topics in philosophy in the last 15 years. The starting point for this is Joshua Gert's paper "Normative Strength and the Balance of Reasons".^[_Philosophical Review_, 2007] In 2016 there was a useful edited collection on the topic by Errol Lord and Barry Maguire.^[Called simply _Weighing Reasons_, and Jussi Suikkanen has a [useful review of it in NDPR](https://ndpr.nd.edu/reviews/weighing-reasons-2/).] And there has been a flood of work since. There are two issues that come up in this literature that I'll briefly mention. 

One important bit of background is that in the usual division of philosophical topics, this has all been taking place in what we think of as ethics, not what we think of as epistemology, let alone probability. But I think it's fundamentally the same set of problems. The folks in the ethics literature have all been talking about weighing _reasons_, but it's commonly (and I think correctly) thought that evidence is a kind of reason, so weighing evidence is the same set of issues.

The topic that has been central to this debate in ethics I don't think is relevant here. Assume that you think that there are actions that are permissible but not obligatory. And not just because they are tied for best with some other actions; they are permissible but other actions are _better_. What should we say about the weight of reasons in favor of the less good, but permissible, action? If it's less than the weight of reasons in favor of the other action, then why is it permissible? If it's the same as the weight of reasons in favor of the other action, why is the other better?

The standard solution here is to say that there are (in the metaphor) two kinds of scales: a permission scale and an obligation scale. And the options are tied on one and not on the other. I don't really love this move; it seems like the two should be integrated more. But anyway, I don't think it's relevant here since I don't think this division between permission and obligation is relevant.^[Maybe that's going to be wrong at the end, given what we say about the _General Theory_. But I think it's a separate issue.]

### Adding Weights

Keynes seems to miss the relevance of a deeply Moorean point here: evidence satisfies an organic unity principle. (Confirmation is holistic, in slightly more updated lingo, but I prefer the Moorean terms.) Think again about the Jack and Jill example. What's the weight of each piece of evidence? Honestly, not that much. But the weight of their sum is, intuitively, substantial.

This is one of the big points in the recent ethics literature, and I think it does create a problem here. The metaphor relies on the idea that bits of evidence are like blocks you put on a scale. But they don't satisfy an organic unity principle. I think this is a reason to be sceptical of the whole 'weighing' metaphor. And without the metaphor, the idea of summing the weights of the two sides is a bit dubious.

### Defeaters

This is in some sense a version of the previous problem, but it's distinctive enough to be worth it's own note. Sometimes, evidence is **defeated**. Here's a famous example.

After Chernobyl melted down, they were understandably worried about the radiation levels in the reactor and the surrounding area. So they got out the trusty Measure-Background-Radiation-Meter, and it read 3.6. That's not great; it should be 0. But it's not bad; it will take months of exposure at 3.6 to develop radiation linked illnesses. Let $a$ be that people are in immediate danger, $h$ the background information (i.e., that there was a meltdown), and $h_1$ the reading of 3.6. Then it seems $a/hh_1 < a/h$, and that $V(a/hh_1) > V(a/h)$.

If you've seen the show, or read about Chernobyl, you know what comes next. It turns out the machine was capped out at 3.6; it simply wouldn't show any higher.^[I read somewhere that the cap was at 1/1000 per second, and the 3.6 was the rate per hour at 1/1000 per second. Capping at 3.6 seemed odd to me, but this might explain it.] Let $h_2$ be that the machine does not have a reading above 3.6. Then $a/hh_1h_2 \approx a/h$. But, and this is the important part, arguably $V(a/hh_1h_2) \approx V(a/h)$. It's not just that the new evidence $h_2$ pushed in the other direction to $h_1$. It's that it showed $h_1$ wasn't really evidence in the first place.

Keynes doesn't have any way of capturing that. His core idea is that new evidence, i.e., evidence that changes our view, adds to the weight. And I don't think that's the case. Sometimes it tells us that what we thought was evidence was not in fact evidence.

There is a small literature on how to model this kind of _defeat_ in probabilistic terms. I don't know it that well, but I didn't get the sense that anyone had a very good idea about what to do. We need a way of differentiating evidence that undermines previous evidence, from evidence that simply points in the opposite direction. Imagine if instead of $h_2$ we'd discovered $h_3$, that people near the reactor had a particular condition that meant even at 3.6 they were in immediate danger. That would raise the probability of $a$ back up, but intuitively in a way that did increase the weight. Just looking at probability kinematics, adding $h_2$ and adding $h_3$ have the same effect, but one decreases weight, the other increases it.

Maybe the idea I floated earlier about a future-directed view could help? In the real world, where we learned $h_2$, we think $h_1$ is useless, _and will remain useless in any realistic scenario_. Maybe after learning $h_1h_3$, there is still some importance to $h_1$ in this inquiry? At least, perhaps it could be relevant given some future learning?

## Weight and Imprecise Probabilities

In a long ago paper^["Keynes, Uncertainty and Interest Rates", in _Cambridge Journal of Economics_] I argued that we should understand $V(a/h)$ using imprecise probabilities. If $S$ is the set of prior probability functions, then $V(a/h) = max(Pr(a|h)) - min(Pr(a|h))$, where the $max$ and $min$ range over the members of $S$. This is massively different to how Keynes understood weight, but at the time I thought it was the best way to capture what was right about the view.

One problem is that because of dilation, on my view weight can go down. At the time I thought that was fine because defeaters imply that weight can go down. But now I don't think this really works. The cases like Chernobyl where weight goes down, are very different to the Gibbon example of dilation.

Another problem is that it implies something Keynes explicitly rejects, namely that $a/h_1 = b/h_2$ implies that $V(a/h_1) = V(b/h_2)$. And I now think the examples in paragraph 4 of chapter 6 are a better case for rejecting that than I'd previous realised.

Here's the case I have in mind. Imagine we have some $\phi$ which (given background $h$) satisfies all the conditions we could want for Indifference, and (also given $h$) the possible satisfiers of $\phi$ are $x,y,z$. Then $\phi(x)/h = 1/3$. Now imagine we also have a die, and we've carefully measured it to see that it's fair, and tested some automated rolling mechanism many times and seen neither bias nor pattern in the rolls. Assume this is also all part of $h$. Let $b$ be that the die will land 1 or 2 on its next roll. Then $b/h = 1/3$ also. But $V(b/h) > V(\phi(x)/h)$, since the former is based on a huge body of evidence, and the latter is based on Indifference.

## Weight in the Economics Work

Assume we can somehow fix these problems and get a notion of weight that works. Is it theoretically useful? In the _Treatise_, Keynes is unsure here. He says that it seems interesting, but he can't see how to give it an application. In the _General Theory_, he does give it an application, and an incredibly interesting one. We are going to talk about this much more in later weeks, but I wanted to flag it here because it's really a pivot point of this course. Here's a key paragraph from the remarkable [chapter 12 of the _General Theory_](http://brian.weatherson.org/general-theory/12.html).

> It would be foolish, in forming our expectations, to attach great weight to matters which are very uncertain. It is reasonable, therefore, to be guided to a considerable degree by the facts about which we feel somewhat confident, even though they may be less decisively relevant to the issue than other facts about which our knowledge is vague and scanty. For this reason the facts of the existing situation enter, in a sense disproportionately, into the formation of our long-term expectations; our usual practice being to take the existing situation and to project it into the future, modified only to the extent that we have more or less definite reasons for expecting a change.

And at the end of the first sentence, we get this footnote.

> By "very uncertain" I do not mean the same thing as "improbable". Cf. my _Treatise on Probability_, chap. 6, on "The Weight of Arguments".

Why is chapter 12 remarkable? Because it doesn't read much like an economics paper, at least not a mainstream one. There are no equations. There are hardly any numbers. It's all about how no one knows anything, and we're all guessing, and we have to basically pretend that we're in a position to do anything like probabilistic reasoning.

The idea that we know very little about what we need in order to invest is a frequently recurring theme in the chapter. I could quote practically the whole thing, but here are a couple more relevant passages.

> The outstanding fact is the extreme precariousness of the basis of knowledge on which our estimates of prospective yield have to be made. Our knowledge of the factors which will govern the yield of an investment some years hence is usually very slight and often negligible. If we speak frankly, we have to admit that our basis of knowledge for estimating the yield ten years hence of a railway, a copper mine, a textile factory, the goodwill of a patent medicine, an Atlantic liner, a building in the City of London amounts to little and sometimes to nothing; or even five years hence. In fact, those who seriously attempt to make any such estimate are often so much in the minority that their behaviour does not govern the market.

And a bit later (this crosses sections 3 and 4 of the chapter), after a discussion of how stock market prices bounce so much during the day:

> How then are these highly significant daily, even hourly, revaluations of existing investments carried out in practice?    
>    
> In practice we have tacitly agreed, as a rule, to fall back on what is, in truth, a convention. The essence of this convention — though it does not, of course, work out quite so simply — lies in assuming that the existing state of affairs will continue indefinitely, except in so far as we have specific reasons to expect a change. This does not mean that we really believe that the existing state of affairs will continue indefinitely. We know from extensive experience that this is most unlikely. The actual results of an investment over a long term of years very seldom agree with the initial expectation. Nor can we rationalise our behaviour by arguing that to a man in a state of ignorance errors in either direction are equally probable, so that there remains a mean actuarial expectation based on equi-probabilities. For it can easily be shown that the assumption of arithmetically equal probabilities based on a state of ignorance leads to absurdities. We are assuming, in effect, that the existing market valuation, however arrived at, is uniquely _correct_ in relation to our existing knowledge of the facts which will influence the yield of the investment, and that it will only change in proportion to changes in this knowledge; though, philosophically speaking it cannot be uniquely correct, since our existing knowledge does not provide a sufficient basis for a calculated mathematical expectation. In point of fact, all sorts of considerations enter into the market valuation which are in no way relevant to the prospective yield.    
>    
> Nevertheless the above conventional method of calculation will be compatible with a considerable measure of continuity and stability in our affairs, _so long as we can rely on the maintenance of the convention_.    
>    
> For if there exist organised investment markets and if we can rely on the maintenance of the convention, an investor can legitimately encourage himself with the idea that the only risk he runs is that of a genuine change in the news _over the near future_, as to the likelihood of which he can attempt to form his own judgment, and which is unlikely to be very large. For, assuming that the convention holds good, it is only these changes which can affect the value of his investment, and he need not lose his sleep merely because he has not any notion what his investment will be worth ten years hence.

And in a contribution the following year to a symposium on the book, he writes:

> By "uncertain" knowledge, let me explain, I do not mean merely to distinguish what is known for certain from what is only probable. The game of roulette is not subject, in this sense, to uncertainty; nor is the prospect of a Victory bond being drawn. Or, again, the expectation of life is only slightly uncertain. Even the weather is only moderately uncertain. The sense in which I am using the term is that in which the prospect of a European war is uncertain, or the price of copper and the rate of interest twenty years hence, or the obsolescence of a new invention, or the position of private wealth-owners in the social system in 1970. About these matters there is no scientific basis on which to form any calculable probability whatever. We simply do not know. Nevertheless, the necessity for action and for decision compels us as practical men to do our best to overlook this awkward fact and to behave exactly as we should if we had behind us a good Benthamite calculation of a series of prospective advantages and disadvantages, each multiplied by its appropriate probability, waiting to be summed.
>    
> How do we manage in such circumstances to behave in a manner which saves our faces as rational, economic men? We have devised for the purpose a variety of techniques, of which much the most important are the three following:
> 
> \(1\) We assume that the present is a much more serviceable guide to the future than a candid examination of past experience would show it to have been hitherto. In other words we largely ignore the prospect of future changes about the actual character of which we know nothing.
>    
> \(2\) We assume that the existing state of opinion as expressed in prices and the character of existing output is based on a _correct_ summing up of future prospects, so that we can accept it as such unless and until something new and relevant comes into the picture.
>    
> (3) Knowing that our own individual judgment is worthless, we endeavor to fall back on the judgment of the rest of the world which is perhaps better informed. That is, we endeavor to conform with the behavior of the majority or the average. The psychology of a society of individuals each of whom is endeavoring to copy the others leads to what we may strictly term a _conventional_ judgment.
> 
> Now a practical theory of the future based on these three principles has certain marked characteristics. In particular, being based on so flimsy a foundation, it is subject to sudden and violent changes. The practice of calmness and immobility, of certainty and security, suddenly breaks down. New fears and hopes will, without warning, take charge of human conduct. The forces of disillusion may suddenly impose a new conventional basis of valuation. All these pretty, polite techniques, made for a well-panelled Board Room and a nicely regulated market, are liable to collapse. At all times the vague panic fears and equally vague and unreasoned hopes are not really lulled, and lie but a little way below the surface.
> 
> Perhaps the reader feels that this general, philosophical disquisition on the behavior of mankind is somewhat remote from the economic theory under discussion. But I think not.

I want to note a few points about this, which we can discuss more in seminar.

1. There is a connection of low weight, in the sense of the _Treatise_ to the very uncertain, in the sense of the _General Theory_. I don't see any other way to read that footnote.
2. We get a lot of examples of "uncertain" things. And, to my eye, they all fit the high value for 
