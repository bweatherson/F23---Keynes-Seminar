---
title: "Week 4: Indifference"
author: "Brian Weatherson"
date: "2023-09-25"
categories: [weekly handout]
abstract: "Keynes discusses the Principle of Indifference, his new name for the best hope we have for getting numerical probabilities out of ignorance."
draft: false
image: "malaprop.jpg"
---

# "Indifference"

Every time I read this chapter I'm surprised again at learning Keynes is responsible for the name "The Principle of Indifference". It has stuck so thoroughly. And it is so much better than "The Principle of Non-Sufficient Reason", which would make everyone think we were about to get into PSR and Leibniz and the cosmological argument. Anyway, it's a good name, for what may or may not be a good principle.

Remember that Keynes thinks it is a wide-open question whether an argument may even have a probability. So let *a* be some proposition wholly disconnected from *h*. Then even if we'd convinced ourselves that *a* / *h* couldn't be any number other than 0.5, it doesn't follow for Keynes that it is 0.5. It might just be non-numerical.

# Counterexamples to Indifference

Keynes kind of goes to town on the PoI in paragraphs 4-9. There are two big things to note here, neither of which I think is always properly reflected in the secondary literature on this problem.

1.  This whole discussion is an in-house argument among people who have broadly epistemic theories of probability. If your response to these examples is "We need to know more about the physical setup, or underlying facts, or ...", then that means you really don't believe the epistemic theory of probability. That's fine - it's a controversial theory. But Keynes isn't arguing with you here; he's talking to his fellow epistemic theorists.
2.  There are a *lot* of examples here. Don't think that by finding some solution to one of them, you've found some general solution to the problems with indifference.

## One that isn't there - the cube factory

The cube factory example that van Fraassen uses in *Laws and Symmetry* isn't quite there in Keynes. A similar example is. Van Fraassen's example is that we know a factory produces perfect cubes of side length at most 2cm. Given that knowledge, and nothing else, what is the probability that the next cube has a side length under 1cm? Related question. We know that a factory produces perfect cubes of volume at most 8cm^3^. Given that knowledge, and nothing else, what is the probability that the next cube has a volume under 1cm^3^? Uh oh, these are the same question, but PoI (Principle of Indifference) says they get different answers.

Keynes will have an example like this, but it's really striking how much variety there is to his counterexamples. One rather often sees people try to resolve the cube factory problem and thereby conclude that they have somehow rescued some version of the PoI.

## Three Book Colours

We know nothing about a book. What's the probability that it (or I guess its cover) is red? What about blue? What about black? If PoI says that they are each 0.5, we get a contradiction given the background knowledge that nothing is red, blue, and black.

Small question: Are these contraries? Surely some covers are blue and red. Does getting clear on the nature of the claim make it more plausible that the PoI wouldn't apply.

## Adding a Detail

Assume we know nothing whatsoever about an object A. Consider the proposition *A is a book*. Since we know nothing about whether it is or isn't a book, PoI says that its probability is 0.5. Now consider the proposition *A is a red book*. Since we know nothing about whether it is or isn't a red book, PoI says that its probability is 0.5. Putting these together, we get that the probability that A is red, conditional on being a book, is 1. That's absurd.

## Having Names for Parts

We know nothing about the world other than that it contains people, each of whom inhabit a point, and that it has regions which have points in them and that Great Britain, France, the British Isles, and Ireland, are among those regions. B is one of the people in the world. By PoI, each of the following are equiprobable: *B is in France*, *B is in Great Britain*, *B is in Ireland*, *B is in the British Isles*. We then learn that the British Isles just are Great Britain plus Ireland.[^1] Either the PoI leads to a contradiction here, or each of these has probability 0, or learning that a region has named parts tells us *a lot* about the probability of people being in it. None of these is particularly plausible.

[^1]: Did Keynes have to do last minute changes to this example after Irish independence?!

## Volume and Density

This is the closest we get to the cube factory (and the one that Keynes most clearly attributes to someone else). Assume we know nothing about a substance except that it's specific volume[^2] is between 1 and 3. PoI suggests that the probability that the specific volume is between 1 and 2 is 0.5. Compare, we get a substance and no nothing except that its specific density[^3] is between 1/3 and 1. By PoI the probability that the specific density is between 1/3 and 2/3 is 0.5. But this is inconsistent with what we say about volumes.

[^2]: i.e., the number of cubic meters occupied by 1kg of the stuff

[^3]: i.e., the inverse of the specific volume; this is not a term in widespread usage these days

Keynes uses a similar example when worrying about averaging prices in his 1909 essay on Index Numbers. Should we average the dollars per unit, or the units per dollars, when finding out the average price of various things? He argues that there is no particular reason to prefer one to the other.

## Bertrand's Chord Example

I'm not going to try explaining this one here, but we possibly should talk through it in class. Again, it feels somewhat like the cube factory, but I'm not sure it is subject to the same objections. (I do think the sphere example is basically the same as the chord example, but I might be misunderstanding the geometry here, since I was never very good at solid geometry.)

The real point Keynes makes is at the end of paragraph 7 about *f*.

# Magnitudes and Learning

This is in a sense another one of the counterexamples to PoI, but I've separated it out because it has such dramatic consequences. Start with a simple case. There is an urn with two balls in it, and all we know is that each ball is black or white, but we do not know the distribution. What does the PoI tell us should be the probability distribution. It turns out there are two different answers here that seem equally plausible at first blush.

First answer. There are three possibilities:

1.  Two black;
2.  One black, one white;
3.  Two white.

Second answer. There are four possibilities:

1.  The first is black, and the second is black.
2.  The first is black, and the second is white.
3.  The first is white, and the second is black.
4.  The first is white, and the second is white.

On the first way of thinking, the PoI says that the probability of an all white urn is 1/3; on the second way of thinking, the PoI says that the probability of an all white urn is 1/4. Keynes goes on to give a reason for thinking the second way is right, and I guess as far as it goes that seems fair.

But think about an example that isn't obviously different in form to this one. There are *n* swans in the world, and all we know *a priori* is that swans are no colour other than black or white. What are the possibilities that PoI says we should be indifferent between. Again, two possibilities jump out.

The first says that we should be indifferent between the *n*+1 possibilities of the form, *There are no white swans*, *There is one white swan*, *There are two white swans*, etc. The second says that we should be indifferent over the 2^*n*^ distribution of black-white over the different swans.

The second does seem in some ways more natural. But it has a shocking consequence. It makes inductive learning impossible. Consider all questions of the following form.

-   Assume you start with the probability distribution recommended by the PoI, and learn that the first *k* swans are white. What, as a function of *k*, is the probability that the next swan is white?

Answer, on the second model, is that it is 1/2 no matter what. That seems absurd, so either (a) the PoI is wrong, or (b) it has been misapplied here, or (c) learning does not go by conditionalisation.

I think this is a problem even for the weaker, heavily qualified, version of the PoI that Keynes ends up endorsing, and it really ends up being a problem for lots of versions of the PoI. It might be, as I once argued, that (c) is the villain here, so this isn't actually a problem for PoI. But it's a worry.

# General Irrelevance

On page 60 Keynes makes a bad slip, and it's going to have significant consequences for us down the line. He is asking when the addition of evidence *h*~1~ is irrelevant to *x*/*h*. He first gives the familiar contemporary answer: it's when *x*/*h* = *x*/*hh*~1~. But then he says something stronger.

> *h*~1~ is irrelevant to x on evidence *h*, if there is no proposition, inferrible from *h*~1~*h* but not from *h*, such that its addition to evidence *h* affects the probability of *x*.

And as I'm sure has been pointed out before (I think I learned it from Carnap's *Logical Foundations of Probability*, but I'm not sure it was new there), this rules out too much. On this definition, practically will be irrelevant. The problem is that the disjunction *h*~1~ $\vee$ *x* is (typically) inferrable from *hh*~1~ but not from *h* alone and (almost always), *x*/*h* \< *x*/*h*(*h*~1~ $\vee$ *x*).

As I said, I think this is, and similar examples, are going to land Keynes in all sorts of hot water. Some of the problems will come up later in this chapter.

I said last week that the sets of probability function model is, I once argued, a pretty good formalisation of Keynes's intuitions. This point is relevant to that idea, in a roundabout way. On the sets of probability functions approach, you really don't get anything like Keynes's general notion of irrelevance. But that's a *good* thing, because we should want to be rid of it, and any part of his theory that relies on it. What parts are those? Well, that's a question we'll need to keep an eye on.

The points at the top of 61, which are nowadays commonplaces, are important observations. Irrelevance (in either Keynes's defective strict sense, or our more familiar loose sense), is closed under negation, and is symmetric. These are sometimes useful things to remember.

# Keynes's Positive Version of the PoI

After so many attacks on the PoI, it is somewhat surprising, to me at least, that Keynes ends the chapter by offering his own version of the PoI. It is very heavily qualified, as we're about to see more qualified than Keynes realises, but it is a version of the PoI. When I got to this part there were two problems I expected to find, which in retrospect I'm not sure were there. But there's a much bigger problem that relates to the previous point about irrelevance.

## Countable Additivity

First, I thought that the PoI would lead to some kind of problem with countable additivity. Keynes is careful to say that he only intends the PoI to apply to finite cases. But it's very hard to get a philosophical principle here that doesn't lead to countable additivity violations. Here's the basic idea.^[Jake Ross has a couple of papers on Sleeping Beauty, one in _Phil Review_ and one in _Phil Studies_ that make a similar point. And I make a similar complaint, less clearly, in my objection to Adam Elga's version of the PoI in an old PPR paper.]

The cash value of Keynes's version of the PoI is the following idea. Let $\phi(x)$ be some propositional radical such that $\exists x x \in S \wedge \phi (x)$ is known (and is more or less trivial) for some set $S$, and so is $\forall x \forall y (\phi(x) \wedge \phi(y)) \rightarrow x = y$ is also trivial. In words, exactly one thing is $\phi$, and it is in $S$. And let the evidence $h$ be symmetric with respect to any two substitution instances $\phi(a), \phi(b)$, at least where $a, b \in S$. Then what Keynes really wants is that $\phi(a)/h = \phi(b)/h$. And that sounds kind of plausible enough, perhaps even after everything that we've seen previously in chapters 3 and 4.

That principle works fine when $S$ is finite; the probability of any one thing being the $\phi$ is $1/|S|$. And it works fine when $S$ is uncountably infinite. The probability of any one thing being the $\phi$ is 0, but that's probably what we want. And you can't deduce any annoying things about cube volumes or substance density from these 0 values.^[Does everyone understand why? Maybe we should pause over this if not.]

But it very much does not work when $S$ is countably infinite. In that case we get that the probability of any one thing being the $\phi$ is 0, but the probability of one of these things being the $\phi$ is 1. So the probability of this countably infinite disjunction, i.e., the first one is the $\phi$, or the second one is, or the third one is, or ..., is not equal to the sum of the probability of the disjuncts.

Now it's a _very big question_ in the last 100 years of philosophy of probability whether countable additivity is a requirement. It's somewhat disappointing that Keynes doesn't really address it. Indeed, he just seems to treat the only salient division among sample spaces to be finite vs infinite, whereas the modern tendency is to treat the big division as finite vs countably infinite vs uncountably infinite. Plenty of people think that it's obviously true that you can have an equiprobable distribution over a countable set, so finite additivity must fail. And there are other reasons people have had for rejecting countable additivity.^[Dmitri Gallow, formerly of this parish, just posted a note arguing against countable additivity on grounds that should appeal to a Keynesian, because it appeals to the idea that conditional distributions are primitive. I think it's a variant on the idea that if X is a flat distribution over the reals in \[0, 1\], then conditionalising on the evidence that X is rational will give you a violation of countable additivity. But that's simplifying Dmitri's views a little bit I suspect.] Still, I think countable additivity is a good constraint, and if the PoI violates it, all the worse for the PoI.^[If we have time, I'll go over the conglomerability argument for countable additivity, and maybe why not everyone buys it.]

## Syntax and Semantics

Keynes's version of the PoI makes heavy use of a _syntactic_ constraint. It's all about whether the competing claims, which are meant to be equiprobable, can be put into the form $\phi(a), \phi(b)$. The contrast is with _semantic_ constraints on indifference principles. Adam Elga, in his [Dr Evil paper](https://philpapers.org/rec/ELGDDE), has such a principle. Two propositions are equiprobable iff there is the right kind of bijection between the sets of centred worlds the two propositions represent.^[There's a bunch of jargon in that last sentence, and I'm more than happy to go over it. But if you don't want to know the details, the big picture point I'm trying to make here is that Elga's version doesn't look at how the two propositions are textually represented, but at the ways in which they are made true.] And it's very natural nowadays to have semantic versions of these principles.

The syntax/semantics split here recurs in a bunch of related fields. It is kind of the same as the debate between proof-theoretic and model-theoretic conceptions of validity in philosophy of logic. And it is kind of the same as the debate between syntactic and semantic conceptions of laws in philosophy of science. And there are probably debates in metaphysics that have the same structure; or, if not, it's only because the semantic side so comprehensively won.

And outside of logic, the semantic side has basically been on a 75 year winning streak, for a fairly simple reason. A very widespread view (which I kind of share) is that syntactic approaches can't help with anything to do with probability/epistemology because of the grue paradox.^[If we have time, I'll definitely go over this.]

Keynes has a syntactic approach for a few reasons. One is that it's the early 20th century, and nobody was using semantic approaches; everything was syntactic. Another was that the grue paradox hadn't been discovered. And a third, perhaps most important, was that Keynes was really committed to the idea that he was extending _logic_ here, and everyone (even the model theorists) agrees that logic has _something_ to do with syntax.

Still, when I read this my first thought was, Ah, Keynes is bringing syntactic weapons to a semantic fight, and this is bound to fail. So I started trying to come up with grue-like counterexamples to his theory. And I didn't quite find them. Because there's a more fundamental problem with the view.

## Disjunctive Parts

Let's look a little more closely at precisely what Keynes says is the constraint on the PoI.

> The Principle of Indifference is applicable to the alternatives $\phi(a)$ and $\phi(b)$, when the evidence $h$ is so constituted that, if $f(a)$ is an independent part of $h$ (see ยง14) which is relevant to $\phi(a)$, and does not contain any independent parts which are irrelevant to $\phi(a)$, then $h$ includes $f(b)$ also.

What is an 'independent part'? When we look back at 14, we find this.

> It will be convenient to define also two other phrases. $h_1$ and $h_2$ are independent and complementary parts of the evidence, if between them they make up $h$ and neither can be inferred from the other. 

But now we have a problem. For any $h, \phi$, we can define an $f$ as follows

$$
f(x) =_{df} h \vee (\phi(a) \wedge x=x)
$$

For any $x$ That is entailed by $h$, and together with $h \vee (\neg \phi(a) \wedge x=x)$ entails $h$. So it is an independent part of $h$. But it is relevant to $\phi(a)$. So for any $h, phi$, there is some independent part of $h$ that is relevant to 